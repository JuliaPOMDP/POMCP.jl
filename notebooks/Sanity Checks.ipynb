{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "addprocs(30);\n",
    "# addprocs(7);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@everywhere begin\n",
    "    using POMDPModels\n",
    "    using POMCP\n",
    "    using POMDPs\n",
    "    import POMDPToolbox.PreviousObservation\n",
    "\n",
    "    import POMCP.belief_from_node\n",
    "    import POMCP.init_V\n",
    "    # import POMCP.POMCPPolicy\n",
    "    import POMDPs.action\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 100000;\n",
    "# N = 100;\n",
    "problem = BabyPOMDP(-5, -10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@everywhere type RandomBabyPolicy <: POMDPs.Policy\n",
    "    rng::AbstractRNG\n",
    "end\n",
    "@everywhere function action(::BabyPOMDP, p::RandomBabyPolicy, b::POMDPs.Belief, a=BabyAction(false))\n",
    "    a.feed = rand(p.rng)>0.5\n",
    "    return a\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "est_reward (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function est_reward(problem, policy, belief, N; eps=0.01)\n",
    "    sum = @parallel (+) for i in 1:N\n",
    "        sim_rng = MersenneTwister(i)\n",
    "        POMDPs.simulate(problem, policy, belief, rng=sim_rng, eps=eps, initial_state=BabyState(false))\n",
    "    end\n",
    "    return sum/N;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 2.739505561 seconds (14213344 bytes allocated)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-16.621810988816325"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feed when Crying (Expected Reward for this nearly-optimal policy is -17.14)\n",
    "# Test from earlier this week with 5000 experiments: -16.72\n",
    "@time est_reward(problem, FeedWhenCrying(), PreviousObservation(BabyObservation(false)), N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is better than in the crying babies test because epsilon is large and, more importantly, it gets a notcrying observation on the first step every time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 0.848669433 seconds (8383672 bytes allocated, 4.92% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-32.17854039299618"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random\n",
    "pol_rng = MersenneTwister(7)\n",
    "@time est_reward(problem, RandomBabyPolicy(pol_rng), PreviousObservation(BabyObservation(false)), N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 3635.754880173 seconds (12027384 bytes allocated, 0.00% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-16.263003916559974"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POMCP with FWC rollout policy\n",
    "# test from earlier this week with 5000 experiments: -16.77\n",
    "rng = MersenneTwister(2)\n",
    "\n",
    "solver = POMCPSolver(FeedWhenCrying(),\n",
    "                     0.01,\n",
    "                     10,\n",
    "                     300, \n",
    "                     rng,\n",
    "                     false,\n",
    "                     PreviousObservationConverter())\n",
    "\n",
    "policy = solve(solver, problem)\n",
    "\n",
    "@time est_reward(problem, policy, POMCPBeliefWrapper(BabyStateDistribution(0.0)), N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 2841.589159556 seconds (2453736 bytes allocated)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-17.209711843801013"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POMCP with Random rollout policy\n",
    "rng = MersenneTwister(2)\n",
    "rollout_pol_rng = MersenneTwister(2)\n",
    "\n",
    "solver = POMCPSolver(RandomBabyPolicy(rollout_pol_rng),\n",
    "                     0.01,\n",
    "                     10,\n",
    "                     300, \n",
    "                     rng,\n",
    "                     false,\n",
    "                     EmptyConverter())\n",
    "\n",
    "policy = solve(solver, problem)\n",
    "\n",
    "@time est_reward(problem, policy, POMCPBeliefWrapper(BabyStateDistribution(0.0)), N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 0.410525487 seconds (1888656 bytes allocated)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-16.16069990155499"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimal policy for these particular problem parameters:\n",
    "# if the belief that the baby is hungry is over .28206, then feed (see DMU book)\n",
    "@everywhere begin\n",
    "    type OptBabyPolicy <: POMDPs.Policy\n",
    "    end\n",
    "    function action(::BabyPOMDP, p::OptBabyPolicy, b::BabyStateDistribution, a=BabyAction(false))\n",
    "        a.feed = b.p_hungry>0.28206\n",
    "        return a\n",
    "    end\n",
    "end\n",
    "@time est_reward(problem, OptBabyPolicy(), BabyStateDistribution(0.0), N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.3.10",
   "language": "julia",
   "name": "julia-0.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
