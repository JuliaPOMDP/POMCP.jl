# POMCP

The Partially Observable Monte Carlo Planning (POMCP) online solver for POMDPs.jl.

Described in

Silver, D., & Veness, J. (2010). Monte-Carlo Planning in Large POMDPs. In *Advances in neural information processing systems* (pp. 2164â€“2172). Retrieved from http://discovery.ucl.ac.uk/1347369/

## Installation

```julia
Pkg.clone("https://github.com/sisl/POMCP.jl.git")
```

## Documentation

This implementation of the POMCP solver may be used to solve POMDPs defined according to the [POMDPs.jl](https://github.com/sisl/POMDPs.jl) interface. Note that this is an online solver, so the computation is carried out as the simulation is running (simulations take a long time, but `solve` takes no time).

For a usage example, see the [Basic Usage](https://github.com/sisl/POMCP.jl/blob/master/notebooks/Basic%20Usage.ipynb) notebook. For some more (poorly documented) examples, see the [Sanity Checks](https://github.com/sisl/POMCP.jl/blob/master/notebooks/Sanity%20Checks.ipynb) notebook.

Behavior is controlled through two mechanisms: solver options and method specializations

### Solver Options

For clarity, a keyword constructor is defined with the following arguments:

- `eps` - Rollout simulations are terminated once the discount factor raised to the current step power is below this (see paper). default: 0.01
- `c` - UCB tuning parameter (see paper). default: 1
- `tree_queries` - Number of nodes created in the tree per action decision.
- `rng` - Random number generator.
- `updater` - A `POMDPs.BeliefUpdater` to be used to update the belief within the policy state. By default the particle filter described in the paper will be used.
- `value_estimate_method` - Either `:value` to use the `POMDPs.value()` function or `rollout` to use a rollout simulation.
- `rollout_policy` - This should be a `POMDPs.Policy` that will be used in rollout simulations. By default a random policy is used.
- `rollout_updater` - The belief updater that will be used in the rollout simulations. default: `updater(rollout_policy)`.
- `num_sparse_actions` - If only a limited number of actions are to be considered, set this. If it is 0, all actions will be considered.

### Methods for Specialization

The following methods can be overridden to change the behavior of the solver:

- `convert_belief(rollout_updater, node)` - When a rollout simulation is started, this method is used to create the initial belief (compatible with `rollout_updater`) based on the appropriate `BeliefNode` at the edge of the tree. By overriding this, a belief can be constructed based on the entire tree or entire state-action history. If this is not overriden, by default it will convert the belief associated with the node directly, i.e. `POMDPs.convert_belief(rollout_updater, node.B)`.
- `init_V(problem, parent, action)` - Defines the initial value (V) associated with a new action node when it is created. This can be used in concert with `init_N` to incorporate prior experience into the solver.
- `init_N(problem, parent, action)` - Defines the initial number of queries (N) associated with a new action node when it is created.
- `sparse_actions(pomdp, state, belief, num_actions)` - If only a limited number of actions are to be considered, this function will be used to generate that set of actions. By default, it simply returns the first `num_actions` actions from the action space generated by `POMDPs.actions`.
- `estimate_value(pomcp, problem, start_state, h)` - This provides an initial unbiased estimate of the value at belief node h. By default it can run a rollout simulation or query the `value()` function in the POMDPs.jl interface. 

## Tree Visualization

Rudimentary interactive visualization of the MCTS tree is available in python notebooks (improving this visualization is something I'd love help on). Run the Display Tree notebook in the notebooks folder for a demo (it doesn't show up in the version of the notebook on github).
