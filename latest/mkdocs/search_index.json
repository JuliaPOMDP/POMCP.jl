{
    "docs": [
        {
            "location": "/", 
            "text": "POMCP.jl\n\n\nThe Partially Observable Monte Carlo Planning (POMCP) online solver for POMDPs.jl.\n\n\nDescribed in\n\n\nSilver, D., \n Veness, J. (2010). Monte-Carlo Planning in Large POMDPs. In \nAdvances in neural information processing systems\n (pp. 2164\u20132172). Retrieved from http://discovery.ucl.ac.uk/1347369/\n\n\n\n\nInstallation\n\n\nSee \nREADME.md\n on the \nGithub repo\n.\n\n\n\n\nDocumentation\n\n\nThis implementation of the POMCP solver may be used to solve POMDPs defined according to the \nPOMDPs.jl\n interface. Note that this is an online solver, so the computation is carried out as the simulation is running (simulations take a long time, but \nsolve\n takes no time).\n\n\nFor a usage example, see the \nBasic Usage\n notebook. For some more (poorly documented) examples, see the \nSanity Checks\n notebook.\n\n\nBehavior is controlled through two mechanisms: \nsolver options\n and \nmethod specializations\n.\n\n\nThere is also an interactive \nsearch tree visualizer\n.", 
            "title": "Home"
        }, 
        {
            "location": "/#pomcpjl", 
            "text": "The Partially Observable Monte Carlo Planning (POMCP) online solver for POMDPs.jl.  Described in  Silver, D.,   Veness, J. (2010). Monte-Carlo Planning in Large POMDPs. In  Advances in neural information processing systems  (pp. 2164\u20132172). Retrieved from http://discovery.ucl.ac.uk/1347369/", 
            "title": "POMCP.jl"
        }, 
        {
            "location": "/#installation", 
            "text": "See  README.md  on the  Github repo .", 
            "title": "Installation"
        }, 
        {
            "location": "/#documentation", 
            "text": "This implementation of the POMCP solver may be used to solve POMDPs defined according to the  POMDPs.jl  interface. Note that this is an online solver, so the computation is carried out as the simulation is running (simulations take a long time, but  solve  takes no time).  For a usage example, see the  Basic Usage  notebook. For some more (poorly documented) examples, see the  Sanity Checks  notebook.  Behavior is controlled through two mechanisms:  solver options  and  method specializations .  There is also an interactive  search tree visualizer .", 
            "title": "Documentation"
        }, 
        {
            "location": "/solver/", 
            "text": "Solver\n\n\nSolver Options are controlled through the POMCPSolver keyword constructor:\n\n\n#\n\n\nPOMCP.POMCPSolver\n \n \nMethod\n.\n\n\nConstructor for the POMCP Solver\n\n\nPOMCPSolver properties are:\n\n\n\n\neps\n - Rollout simulations are terminated once the discount factor raised to the current step power is below this (see paper). default: 0.01\n\n\nmax_depth\n - Rollout simulations and tree expansion are terminated at this depth. default: typemax(Int)\n\n\nc\n - UCB tuning parameter (see paper). default: 1\n\n\ntree_queries\n - Number of nodes created in the tree per action decision.\n\n\nrng\n - Random number generator.\n\n\nnode_belief_updater\n - A \nPOMDPs.Updater\n to be used to update the belief in the nodes of the belief tree. By default the particle filter described in the paper will be used.\n\n\nvalue_estimate_method\n - Either \n:value\n to use the \nPOMDPs.value()\n function or \n:rollout\n to use a rollout simulation.\n\n\nrollout_solver\n - This should be a \nPOMDPs.Solver\n or \nPOMDPs.Policy\n that will be used in rollout simulations. If it is a \nSolver\n, \nsolve\n will be called to determine the rollout policy. By default a random policy is used.\n\n\nnum_sparse_actions\n - If only a limited number of actions are to be considered, set this. If it is 0, all actions will be considered.", 
            "title": "Solver"
        }, 
        {
            "location": "/solver/#solver", 
            "text": "Solver Options are controlled through the POMCPSolver keyword constructor:  #  POMCP.POMCPSolver     Method .  Constructor for the POMCP Solver  POMCPSolver properties are:   eps  - Rollout simulations are terminated once the discount factor raised to the current step power is below this (see paper). default: 0.01  max_depth  - Rollout simulations and tree expansion are terminated at this depth. default: typemax(Int)  c  - UCB tuning parameter (see paper). default: 1  tree_queries  - Number of nodes created in the tree per action decision.  rng  - Random number generator.  node_belief_updater  - A  POMDPs.Updater  to be used to update the belief in the nodes of the belief tree. By default the particle filter described in the paper will be used.  value_estimate_method  - Either  :value  to use the  POMDPs.value()  function or  :rollout  to use a rollout simulation.  rollout_solver  - This should be a  POMDPs.Solver  or  POMDPs.Policy  that will be used in rollout simulations. If it is a  Solver ,  solve  will be called to determine the rollout policy. By default a random policy is used.  num_sparse_actions  - If only a limited number of actions are to be considered, set this. If it is 0, all actions will be considered.", 
            "title": "Solver"
        }, 
        {
            "location": "/methods/", 
            "text": "Methods for Specialization\n\n\nThe following methods can be overridden to change the behavior of the solver:\n\n\n#\n\n\nPOMCP.extract_belief\n \n \nMethod\n.\n\n\n#\n\n\nPOMCP.init_V\n \n \nMethod\n.\n\n\n#\n\n\nPOMCP.init_N\n \n \nMethod\n.\n\n\n#\n\n\nPOMCP.sparse_actions\n \n \nMethod\n.\n\n\n#\n\n\nPOMCP.estimate_value\n \n \nMethod\n.", 
            "title": "Methods"
        }, 
        {
            "location": "/methods/#methods-for-specialization", 
            "text": "The following methods can be overridden to change the behavior of the solver:  #  POMCP.extract_belief     Method .  #  POMCP.init_V     Method .  #  POMCP.init_N     Method .  #  POMCP.sparse_actions     Method .  #  POMCP.estimate_value     Method .", 
            "title": "Methods for Specialization"
        }, 
        {
            "location": "/visualization/", 
            "text": "Tree Visualization\n\n\nInteractive visualization of the MCTS tree is available in Jupyter notebooks. Run the Display Tree notebook in the notebooks folder for a demonstration, or view it here: \nhttp://nbviewer.jupyter.org/github/JuliaPOMDP/POMCP.jl/blob/master/notebooks/Display_Tree.ipynb\n\n\nIn order to display a tree, create a POMCPTreeVisualizer with any BeliefNode. If the last line of a cell in a Jupyter notebook returns a POMCPTreeVisualizer, the output cell will be populated with html and javascript that display the tree. See the documentation for MCTS.jl for more detailed information about the tree and instructions describing how to customize its appearance. In particular, the \nnode_tag\n and \ntooltip_tag\n functions can be overridden to customize how actions and observations are displayed.", 
            "title": "Visualization"
        }, 
        {
            "location": "/visualization/#tree-visualization", 
            "text": "Interactive visualization of the MCTS tree is available in Jupyter notebooks. Run the Display Tree notebook in the notebooks folder for a demonstration, or view it here:  http://nbviewer.jupyter.org/github/JuliaPOMDP/POMCP.jl/blob/master/notebooks/Display_Tree.ipynb  In order to display a tree, create a POMCPTreeVisualizer with any BeliefNode. If the last line of a cell in a Jupyter notebook returns a POMCPTreeVisualizer, the output cell will be populated with html and javascript that display the tree. See the documentation for MCTS.jl for more detailed information about the tree and instructions describing how to customize its appearance. In particular, the  node_tag  and  tooltip_tag  functions can be overridden to customize how actions and observations are displayed.", 
            "title": "Tree Visualization"
        }
    ]
}