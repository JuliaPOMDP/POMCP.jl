{
    "docs": [
        {
            "location": "/", 
            "text": "POMCP.jl\n\n\nThe Partially Observable Monte Carlo Planning (POMCP) online solver for POMDPs.jl.\n\n\nDescribed in\n\n\nSilver, D., \n Veness, J. (2010). Monte-Carlo Planning in Large POMDPs. In \nAdvances in neural information processing systems\n (pp. 2164\u20132172). Retrieved from http://discovery.ucl.ac.uk/1347369/\n\n\n\n\nInstallation\n\n\nSee \nREADME.md\n on the \nGithub repo\n.\n\n\n\n\nDocumentation\n\n\n\n\nBasics\n\n\nThis implementation of the POMCP solver may be used to solve POMDPs defined according to the \nPOMDPs.jl\n interface. Note that this is an online solver, so the computation is carried out as the simulation is running (simulations take a long time, but \nsolve\n takes no time).\n\n\nFor a usage example, see the \nBasic Usage\n notebook. For some more (poorly documented) examples, see the \nSanity Checks\n notebook.\n\n\nBehavior is controlled through two mechanisms: \nsolver options\n and \nmethod specializations\n.\n\n\n\n\nBelief Updates\n\n\nBy default, POMCP uses an unweighted particle filter for belief updates as discussed in the original paper describing it. However, this implementation can use any Updater to keep track of the belief. A notebook describing the various belief updater options and features can be viewed here: \nhttp://nbviewer.jupyter.org/github/JuliaPOMDP/POMCP.jl/blob/master/notebooks/Belief_and_Particle_Filter_Options.ipynb\n\n\n\n\nTree Visualization\n\n\nInteractive visualization of the POMCP tree is available in Jupyter notebooks. Run the Display Tree notebook in the notebooks folder for a demonstration, or view it here: \nhttp://nbviewer.jupyter.org/github/JuliaPOMDP/POMCP.jl/blob/master/notebooks/Display_Tree.ipynb\n\n\nIn order to display a tree, create a POMCPTreeVisualizer with any BeliefNode. If the last line of a cell in a Jupyter notebook returns a POMCPTreeVisualizer, the output cell will be populated with html and javascript that display the tree. See the documentation for MCTS.jl for more detailed information about the tree and instructions describing how to customize its appearance. In particular, the \nnode_tag\n and \ntooltip_tag\n functions can be overridden to customize how actions and observations are displayed.", 
            "title": "Home"
        }, 
        {
            "location": "/#pomcpjl", 
            "text": "The Partially Observable Monte Carlo Planning (POMCP) online solver for POMDPs.jl.  Described in  Silver, D.,   Veness, J. (2010). Monte-Carlo Planning in Large POMDPs. In  Advances in neural information processing systems  (pp. 2164\u20132172). Retrieved from http://discovery.ucl.ac.uk/1347369/", 
            "title": "POMCP.jl"
        }, 
        {
            "location": "/#installation", 
            "text": "See  README.md  on the  Github repo .", 
            "title": "Installation"
        }, 
        {
            "location": "/#documentation", 
            "text": "", 
            "title": "Documentation"
        }, 
        {
            "location": "/#basics", 
            "text": "This implementation of the POMCP solver may be used to solve POMDPs defined according to the  POMDPs.jl  interface. Note that this is an online solver, so the computation is carried out as the simulation is running (simulations take a long time, but  solve  takes no time).  For a usage example, see the  Basic Usage  notebook. For some more (poorly documented) examples, see the  Sanity Checks  notebook.  Behavior is controlled through two mechanisms:  solver options  and  method specializations .", 
            "title": "Basics"
        }, 
        {
            "location": "/#belief-updates", 
            "text": "By default, POMCP uses an unweighted particle filter for belief updates as discussed in the original paper describing it. However, this implementation can use any Updater to keep track of the belief. A notebook describing the various belief updater options and features can be viewed here:  http://nbviewer.jupyter.org/github/JuliaPOMDP/POMCP.jl/blob/master/notebooks/Belief_and_Particle_Filter_Options.ipynb", 
            "title": "Belief Updates"
        }, 
        {
            "location": "/#tree-visualization", 
            "text": "Interactive visualization of the POMCP tree is available in Jupyter notebooks. Run the Display Tree notebook in the notebooks folder for a demonstration, or view it here:  http://nbviewer.jupyter.org/github/JuliaPOMDP/POMCP.jl/blob/master/notebooks/Display_Tree.ipynb  In order to display a tree, create a POMCPTreeVisualizer with any BeliefNode. If the last line of a cell in a Jupyter notebook returns a POMCPTreeVisualizer, the output cell will be populated with html and javascript that display the tree. See the documentation for MCTS.jl for more detailed information about the tree and instructions describing how to customize its appearance. In particular, the  node_tag  and  tooltip_tag  functions can be overridden to customize how actions and observations are displayed.", 
            "title": "Tree Visualization"
        }, 
        {
            "location": "/solver/", 
            "text": "Solver\n\n\nSolver options are controlled through the solver keyword constructor:\n\n\n#\n\n\nPOMCP.POMCPSolver\n \n \nType\n.\n\n\nPOMCP Solver type\n\n\nFields:\n\n\neps::Float64\n    Rollouts and tree expansion will stop when discount^depth is less than this.\n    default: 0.01\n\nmax_depth::Int\n    Rollouts and tree expension will stop when this depth is reached.\n    default: 10\n\nc::Float64\n    UCB exploration constant - specifies how much the solver should explore.\n    default: 1.0\n\ntree_queries::Int\n    Number of iterations during each action() call.\n    default: 100\n\nrng::AbstractRNG\n    Random number generator.\n    default: Base.GLOBAL_RNG\n\nnode_belief_updater::Updater\n    Calculates the belief for a new belief node (see notebooks/Belief_and_Particle_Filter_Options.ipynb for more info.)\n    default: DefaultReinvigoratorStub() - this will simply keep the particles as described in the paper without doing any reinvigoration.\n\nestimate_value::Any (rollout policy can be specified by setting this to RolloutEstimator(policy))\n    Function, object, or number used to estimate the value at the leaf nodes.\n    If this is a function `f`, `f(pomdp, s, h::BeliefNode, steps)` will be called to estimate the value.\n    If this is an object `o`, `estimate_value(o, pomdp, s, h::BeliefNode, steps)` will be called.\n    If this is a number, the value will be set to that number\n    default: RolloutEstimator(RandomSolver(rng))\n\ninit_V::Any\n    Function, object, or number used to set the initial V(h,a) value at a new node.\n    If this is a function `f`, `f(pomdp, h, a)` will be called to set the value.\n    If this is an object `o`, `init_V(o, pomdp, h, a)` will be called.\n    If this is a number, V will be set to that number\n    default: 0.0\n\ninit_N::Any\n    Function, object, or number used to set the initial N(s,a) value at a new node.\n    If this is a function `f`, `f(pomdp, h, a)` will be called to set the value.\n    If this is an object `o`, `init_N(o, pomdp, h, a)` will be called.\n    If this is a number, N will be set to that number\n    default: 0\n\nnum_sparse_actions::Int\n    Number of actions to be considered at each node.\n    If \n= 0, the entire action space will be considered.\n    default: 0\n\n\n\n\nsource\n\n\n#\n\n\nPOMCP.POMCPDPWSolver\n \n \nType\n.\n\n\nPOMCP Solver type\n\n\nFields:\n\n\neps::Float64\n    Rollouts and tree expansion will stop when discount^depth is less than this.\n    default: 0.01\n\nmax_depth::Int\n    Rollouts and tree expension will stop when this depth is reached.\n    default: 10\n\nc::Float64\n    UCB exploration constant - specifies how much the solver should explore.\n    default: 1.0\n\ntree_queries::Int\n    Number of iterations during each action() call.\n    default: 100\n\nrng::AbstractRNG\n    Random number generator.\n    default: Base.GLOBAL_RNG\n\nnode_belief_updater::Updater\n    Calculates the belief for a new belief node (see notebooks/Belief_and_Particle_Filter_Options.ipynb for more info.)\n    default: DefaultReinvigoratorStub() - this will simply keep the particles as described in the paper without doing any reinvigoration.\n\nestimate_value::Any (rollout policy can be specified by setting this to RolloutEstimator(policy))\n    Function, object, or number used to estimate the value at the leaf nodes.\n    If this is a function `f`, `f(pomdp, s, h::BeliefNode, steps)` will be called to estimate the value.\n    If this is an object `o`, `estimate_value(o, pomdp, s, h::BeliefNode, steps)` will be called.\n    If this is a number, the value will be set to that number\n    default: RolloutEstimator(RandomSolver(rng))\n\nenable_action_pw::Bool\n    Turn progressive widening of the number of actions considered on or off.\n    If false, all actions will be considered.\n    default: true\n\nk_action::Float64\nalpha_action::Float64\nk_state::Float64\nalpha_state::Float64\n    These constants control the double progressive widening. A new observation\n    or action will be added if the number of children is less than or equal to kN^alpha.\n    defaults: k:10, alpha:0.5\n\ninit_V::Any\n    Function, object, or number used to set the initial V(h,a) value at a new node.\n    If this is a function `f`, `f(pomdp, h, a)` will be called to set the value.\n    If this is an object `o`, `init_V(o, pomdp, h, a)` will be called.\n    If this is a number, V will be set to that number\n    default: 0.0\n\ninit_N::Any\n    Function, object, or number used to set the initial N(s,a) value at a new node.\n    If this is a function `f`, `f(pomdp, h, a)` will be called to set the value.\n    If this is an object `o`, `init_N(o, pomdp, h, a)` will be called.\n    If this is a number, N will be set to that number\n    default: 0\n\nnext_action::Any\n    Function or object used to choose the next action to be considered for progressive widening.\n    The next action is determined based on the POMDP, the belief, `b`, and the current `BeliefNode`, `h`.\n    If this is a function `f`, `f(pomdp, b, h)` will be called to set the value.\n    If this is an object `o`, `next_action(o, pomdp, b, h)` will be called.\n    default: RandomActionGenerator(rng)\n\n\n\n\nFor more information on the k and alpha parameters, see Cou\u00ebtoux, A., Hoock, J.-B., Sokolovska, N., Teytaud, O., \n Bonnard, N. (2011). Continuous Upper Confidence Trees. In Learning and Intelligent Optimization. Rome, Italy. Retrieved from http://link.springer.com/chapter/10.1007/978-3-642-25566-3_32\n\n\nsource", 
            "title": "Solver"
        }, 
        {
            "location": "/solver/#solver", 
            "text": "Solver options are controlled through the solver keyword constructor:  #  POMCP.POMCPSolver     Type .  POMCP Solver type  Fields:  eps::Float64\n    Rollouts and tree expansion will stop when discount^depth is less than this.\n    default: 0.01\n\nmax_depth::Int\n    Rollouts and tree expension will stop when this depth is reached.\n    default: 10\n\nc::Float64\n    UCB exploration constant - specifies how much the solver should explore.\n    default: 1.0\n\ntree_queries::Int\n    Number of iterations during each action() call.\n    default: 100\n\nrng::AbstractRNG\n    Random number generator.\n    default: Base.GLOBAL_RNG\n\nnode_belief_updater::Updater\n    Calculates the belief for a new belief node (see notebooks/Belief_and_Particle_Filter_Options.ipynb for more info.)\n    default: DefaultReinvigoratorStub() - this will simply keep the particles as described in the paper without doing any reinvigoration.\n\nestimate_value::Any (rollout policy can be specified by setting this to RolloutEstimator(policy))\n    Function, object, or number used to estimate the value at the leaf nodes.\n    If this is a function `f`, `f(pomdp, s, h::BeliefNode, steps)` will be called to estimate the value.\n    If this is an object `o`, `estimate_value(o, pomdp, s, h::BeliefNode, steps)` will be called.\n    If this is a number, the value will be set to that number\n    default: RolloutEstimator(RandomSolver(rng))\n\ninit_V::Any\n    Function, object, or number used to set the initial V(h,a) value at a new node.\n    If this is a function `f`, `f(pomdp, h, a)` will be called to set the value.\n    If this is an object `o`, `init_V(o, pomdp, h, a)` will be called.\n    If this is a number, V will be set to that number\n    default: 0.0\n\ninit_N::Any\n    Function, object, or number used to set the initial N(s,a) value at a new node.\n    If this is a function `f`, `f(pomdp, h, a)` will be called to set the value.\n    If this is an object `o`, `init_N(o, pomdp, h, a)` will be called.\n    If this is a number, N will be set to that number\n    default: 0\n\nnum_sparse_actions::Int\n    Number of actions to be considered at each node.\n    If  = 0, the entire action space will be considered.\n    default: 0  source  #  POMCP.POMCPDPWSolver     Type .  POMCP Solver type  Fields:  eps::Float64\n    Rollouts and tree expansion will stop when discount^depth is less than this.\n    default: 0.01\n\nmax_depth::Int\n    Rollouts and tree expension will stop when this depth is reached.\n    default: 10\n\nc::Float64\n    UCB exploration constant - specifies how much the solver should explore.\n    default: 1.0\n\ntree_queries::Int\n    Number of iterations during each action() call.\n    default: 100\n\nrng::AbstractRNG\n    Random number generator.\n    default: Base.GLOBAL_RNG\n\nnode_belief_updater::Updater\n    Calculates the belief for a new belief node (see notebooks/Belief_and_Particle_Filter_Options.ipynb for more info.)\n    default: DefaultReinvigoratorStub() - this will simply keep the particles as described in the paper without doing any reinvigoration.\n\nestimate_value::Any (rollout policy can be specified by setting this to RolloutEstimator(policy))\n    Function, object, or number used to estimate the value at the leaf nodes.\n    If this is a function `f`, `f(pomdp, s, h::BeliefNode, steps)` will be called to estimate the value.\n    If this is an object `o`, `estimate_value(o, pomdp, s, h::BeliefNode, steps)` will be called.\n    If this is a number, the value will be set to that number\n    default: RolloutEstimator(RandomSolver(rng))\n\nenable_action_pw::Bool\n    Turn progressive widening of the number of actions considered on or off.\n    If false, all actions will be considered.\n    default: true\n\nk_action::Float64\nalpha_action::Float64\nk_state::Float64\nalpha_state::Float64\n    These constants control the double progressive widening. A new observation\n    or action will be added if the number of children is less than or equal to kN^alpha.\n    defaults: k:10, alpha:0.5\n\ninit_V::Any\n    Function, object, or number used to set the initial V(h,a) value at a new node.\n    If this is a function `f`, `f(pomdp, h, a)` will be called to set the value.\n    If this is an object `o`, `init_V(o, pomdp, h, a)` will be called.\n    If this is a number, V will be set to that number\n    default: 0.0\n\ninit_N::Any\n    Function, object, or number used to set the initial N(s,a) value at a new node.\n    If this is a function `f`, `f(pomdp, h, a)` will be called to set the value.\n    If this is an object `o`, `init_N(o, pomdp, h, a)` will be called.\n    If this is a number, N will be set to that number\n    default: 0\n\nnext_action::Any\n    Function or object used to choose the next action to be considered for progressive widening.\n    The next action is determined based on the POMDP, the belief, `b`, and the current `BeliefNode`, `h`.\n    If this is a function `f`, `f(pomdp, b, h)` will be called to set the value.\n    If this is an object `o`, `next_action(o, pomdp, b, h)` will be called.\n    default: RandomActionGenerator(rng)  For more information on the k and alpha parameters, see Cou\u00ebtoux, A., Hoock, J.-B., Sokolovska, N., Teytaud, O.,   Bonnard, N. (2011). Continuous Upper Confidence Trees. In Learning and Intelligent Optimization. Rome, Italy. Retrieved from http://link.springer.com/chapter/10.1007/978-3-642-25566-3_32  source", 
            "title": "Solver"
        }, 
        {
            "location": "/methods/", 
            "text": "Methods for Specialization\n\n\nThe following methods can be overridden to change the behavior of the solver:\n\n\n#\n\n\nPOMCP.extract_belief\n \n \nFunction\n.\n\n\nextract_belief(rollout_updater::POMDPs.Updater, node::ObsNode) = initialize_belief(rollout_updater, node.B)\n\n\n\n\nReturn a belief compatible with the \nrollout_updater\n from the belief in \nnode\n.\n\n\nWhen a rollout simulation is started, this method is used to create the initial belief (compatible with \nrollout_updater\n) based on the appropriate \nBeliefNode\n at the edge of the tree. By overriding this, a belief can be constructed based on the entire tree or entire observation-action history. If this is not overriden, by default it will use initialize_belief on the belief associated with the node directly, i.e. \nPOMDPs.initialize_belief(rollout_updater, node.B)\n.\n\n\nsource\n\n\n#\n\n\nPOMCP.sparse_actions\n \n \nFunction\n.\n\n\nsparse_actions(pomcp::POMCPPlanner, pomdp::POMDPs.POMDP, h::BeliefNode, num_actions::Int)\n\n\n\n\nReturn an iterable object containing no more than \nnum_actions\n actions to be considered at the current node.\n\n\nOverride this if you want to choose specific actions (you can override based on the POMDP type at the node level, or the belief type). If only a limited number of actions are to be considered, this function will be used to generate that set of actions. By default, it simply returns a random sampling of actions from the action space generated by \nPOMDPs.actions\n.\n\n\nIf your problem has a continuous action space, you will want to override this to try a sensible set of action samples.\n\n\nsource", 
            "title": "Methods"
        }, 
        {
            "location": "/methods/#methods-for-specialization", 
            "text": "The following methods can be overridden to change the behavior of the solver:  #  POMCP.extract_belief     Function .  extract_belief(rollout_updater::POMDPs.Updater, node::ObsNode) = initialize_belief(rollout_updater, node.B)  Return a belief compatible with the  rollout_updater  from the belief in  node .  When a rollout simulation is started, this method is used to create the initial belief (compatible with  rollout_updater ) based on the appropriate  BeliefNode  at the edge of the tree. By overriding this, a belief can be constructed based on the entire tree or entire observation-action history. If this is not overriden, by default it will use initialize_belief on the belief associated with the node directly, i.e.  POMDPs.initialize_belief(rollout_updater, node.B) .  source  #  POMCP.sparse_actions     Function .  sparse_actions(pomcp::POMCPPlanner, pomdp::POMDPs.POMDP, h::BeliefNode, num_actions::Int)  Return an iterable object containing no more than  num_actions  actions to be considered at the current node.  Override this if you want to choose specific actions (you can override based on the POMDP type at the node level, or the belief type). If only a limited number of actions are to be considered, this function will be used to generate that set of actions. By default, it simply returns a random sampling of actions from the action space generated by  POMDPs.actions .  If your problem has a continuous action space, you will want to override this to try a sensible set of action samples.  source", 
            "title": "Methods for Specialization"
        }
    ]
}